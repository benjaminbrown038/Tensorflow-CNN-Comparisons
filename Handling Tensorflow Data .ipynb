{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np \n",
    "import tensorflow \n",
    "import tensorflow.keras.preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths \n",
    "image = 'mnist_png/training/0/1.png'\n",
    "training = 'mnist_png/training'\n",
    "testing = 'mnist_png/testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    file_path = Path(file_path)\n",
    "    stacked_data = np.concatenate((np.array([(Image.open(i)) for i in file_path])))\n",
    "    return stacked_data\n",
    "\n",
    "def Image_Data_Generator(file_path,**kwargs):\n",
    "    img = tensorflow.keras.preprocessing.image.ImageDataGenerator()\n",
    "    data = img.flow_from_directory(file_path,**kwargs)\n",
    "    return data\n",
    "\n",
    "def image_to_array(image):\n",
    "    array = tensorflow.keras.preprocessing.image.img_to_array(image_to_array)\n",
    "    return array\n",
    "\n",
    "def array_to_image(array):\n",
    "    image = tensorflow.keras.preprocessing.image.array_to_img(image)\n",
    "    return image\n",
    "\n",
    "def keras_data_handling_independent(image_generator_object):\n",
    "    length = len(image_generator_object)\n",
    "    mini_batch = (image_generator_object[0][0].shape)[0]\n",
    "    list1 = []\n",
    "    for i in range(length):\n",
    "        for j in range(mini_batch):\n",
    "            new_array = image_generator_object[i][0][j]\n",
    "            array = np.expand_dims(new_array,axis=0)\n",
    "            list1.append(array)\n",
    "    data = np.concatenate(list1)\n",
    "    return data\n",
    "\n",
    "def keras_data_handling_dependent(image_generator_object):\n",
    "    length = len(image_generator_object)\n",
    "    mini_batch = (image_generator_object[0][0].shape)[0]\n",
    "    list1 = []\n",
    "    for i in range(length):\n",
    "        for j in range(mini_batch):\n",
    "            new_array = image_generator_object[i][0][j]\n",
    "            array = np.expand_dims(new_array,axis=0)\n",
    "            list1.append(array)\n",
    "    data = np.concatenate(list1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "training = Image_Data_Generator(training,target_size=(28,28),\n",
    "                                color_mode=\"grayscale\",\n",
    "                                batch_size = 60000)\n",
    "independent_training_data = np.array([training[0][0]])\n",
    "dependent_training_data = np.array([training[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "testing = Image_Data_Generator(testing,batch_size = 10000,\n",
    "                               color_mode='grayscale',\n",
    "                              target_size = (28,28))\n",
    "independent_testing_data = (np.array([testing[0][0]]))\n",
    "dependent_testing_data = (np.array(testing[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8,kernel_size=(3,3),padding='same',data_format = 'channels_last',input_shape = (28,28,1), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3),padding='same'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3),padding='same'))\n",
    "model.add(Conv2D(128,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3),padding='same'))\n",
    "model.add(Conv2D(10,kernel_size=(3,3),padding='same',activation='softmax'))\n",
    "model.add(MaxPool2D(pool_size=(3,3),padding='same'))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tensorflow.keras.optimizers.Adam(lr=.001)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = opt,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:6 out of the last 64 calls to <function Model.make_train_function.<locals>.train_function at 0x149ad5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 64 calls to <function Model.make_test_function.<locals>.test_function at 0x13d584378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 - 2s - loss: 10.6719 - accuracy: 0.0966 - val_loss: 9.0379 - val_accuracy: 0.0747\n",
      "Epoch 2/100\n",
      "1/1 - 2s - loss: 8.9758 - accuracy: 0.0765 - val_loss: 9.3687 - val_accuracy: 0.1485\n",
      "Epoch 3/100\n",
      "1/1 - 2s - loss: 9.3690 - accuracy: 0.1493 - val_loss: 9.8061 - val_accuracy: 0.1135\n",
      "Epoch 4/100\n",
      "1/1 - 3s - loss: 9.7563 - accuracy: 0.1123 - val_loss: 9.5242 - val_accuracy: 0.1135\n",
      "Epoch 5/100\n",
      "1/1 - 2s - loss: 9.4438 - accuracy: 0.1124 - val_loss: 8.6209 - val_accuracy: 0.1665\n",
      "Epoch 6/100\n",
      "1/1 - 2s - loss: 8.5948 - accuracy: 0.1714 - val_loss: 9.0474 - val_accuracy: 0.1950\n",
      "Epoch 7/100\n",
      "1/1 - 4s - loss: 9.0323 - accuracy: 0.1936 - val_loss: 8.7350 - val_accuracy: 0.2045\n",
      "Epoch 8/100\n",
      "1/1 - 4s - loss: 8.7036 - accuracy: 0.2039 - val_loss: 8.6074 - val_accuracy: 0.2002\n",
      "Epoch 9/100\n",
      "1/1 - 3s - loss: 8.5779 - accuracy: 0.2000 - val_loss: 8.6182 - val_accuracy: 0.1860\n",
      "Epoch 10/100\n",
      "1/1 - 2s - loss: 8.5950 - accuracy: 0.1870 - val_loss: 8.6662 - val_accuracy: 0.1708\n",
      "Epoch 11/100\n",
      "1/1 - 2s - loss: 8.6431 - accuracy: 0.1738 - val_loss: 8.7006 - val_accuracy: 0.1632\n",
      "Epoch 12/100\n",
      "1/1 - 2s - loss: 8.6777 - accuracy: 0.1669 - val_loss: 8.6882 - val_accuracy: 0.1665\n",
      "Epoch 13/100\n",
      "1/1 - 2s - loss: 8.6662 - accuracy: 0.1701 - val_loss: 8.6491 - val_accuracy: 0.1791\n",
      "Epoch 14/100\n",
      "1/1 - 2s - loss: 8.6266 - accuracy: 0.1802 - val_loss: 8.6185 - val_accuracy: 0.1908\n",
      "Epoch 15/100\n",
      "1/1 - 2s - loss: 8.5919 - accuracy: 0.1916 - val_loss: 8.6030 - val_accuracy: 0.2018\n",
      "Epoch 16/100\n",
      "1/1 - 2s - loss: 8.5737 - accuracy: 0.2005 - val_loss: 8.6003 - val_accuracy: 0.2060\n",
      "Epoch 17/100\n",
      "1/1 - 2s - loss: 8.5682 - accuracy: 0.2046 - val_loss: 8.6097 - val_accuracy: 0.2067\n",
      "Epoch 18/100\n",
      "1/1 - 2s - loss: 8.5726 - accuracy: 0.2061 - val_loss: 8.6239 - val_accuracy: 0.2055\n",
      "Epoch 19/100\n",
      "1/1 - 2s - loss: 8.5827 - accuracy: 0.2051 - val_loss: 8.6359 - val_accuracy: 0.2045\n",
      "Epoch 20/100\n",
      "1/1 - 2s - loss: 8.5925 - accuracy: 0.2029 - val_loss: 8.6404 - val_accuracy: 0.2035\n",
      "Epoch 21/100\n",
      "1/1 - 2s - loss: 8.5962 - accuracy: 0.2016 - val_loss: 8.6357 - val_accuracy: 0.2042\n",
      "Epoch 22/100\n",
      "1/1 - 2s - loss: 8.5919 - accuracy: 0.2023 - val_loss: 8.6251 - val_accuracy: 0.2053\n",
      "Epoch 23/100\n",
      "1/1 - 2s - loss: 8.5828 - accuracy: 0.2044 - val_loss: 8.6133 - val_accuracy: 0.2056\n",
      "Epoch 24/100\n",
      "1/1 - 2s - loss: 8.5735 - accuracy: 0.2062 - val_loss: 8.6041 - val_accuracy: 0.2077\n",
      "Epoch 25/100\n",
      "1/1 - 3s - loss: 8.5669 - accuracy: 0.2068 - val_loss: 8.5991 - val_accuracy: 0.2078\n",
      "Epoch 26/100\n",
      "1/1 - 2s - loss: 8.5642 - accuracy: 0.2067 - val_loss: 8.5978 - val_accuracy: 0.2072\n",
      "Epoch 27/100\n",
      "1/1 - 2s - loss: 8.5642 - accuracy: 0.2051 - val_loss: 8.5992 - val_accuracy: 0.2055\n",
      "Epoch 28/100\n",
      "1/1 - 2s - loss: 8.5660 - accuracy: 0.2034 - val_loss: 8.6016 - val_accuracy: 0.2034\n",
      "Epoch 29/100\n",
      "1/1 - 2s - loss: 8.5683 - accuracy: 0.2016 - val_loss: 8.6031 - val_accuracy: 0.2015\n",
      "Epoch 30/100\n",
      "1/1 - 2s - loss: 8.5700 - accuracy: 0.2004 - val_loss: 8.6036 - val_accuracy: 0.2009\n",
      "Epoch 31/100\n",
      "1/1 - 2s - loss: 8.5704 - accuracy: 0.2001 - val_loss: 8.6028 - val_accuracy: 0.2013\n",
      "Epoch 32/100\n",
      "1/1 - 3s - loss: 8.5694 - accuracy: 0.2005 - val_loss: 8.6014 - val_accuracy: 0.2029\n",
      "Epoch 33/100\n",
      "1/1 - 3s - loss: 8.5675 - accuracy: 0.2013 - val_loss: 8.6000 - val_accuracy: 0.2044\n",
      "Epoch 34/100\n",
      "1/1 - 3s - loss: 8.5655 - accuracy: 0.2027 - val_loss: 8.5988 - val_accuracy: 0.2059\n",
      "Epoch 35/100\n",
      "1/1 - 4s - loss: 8.5639 - accuracy: 0.2042 - val_loss: 8.5980 - val_accuracy: 0.2070\n",
      "Epoch 36/100\n",
      "1/1 - 3s - loss: 8.5627 - accuracy: 0.2053 - val_loss: 8.5976 - val_accuracy: 0.2076\n",
      "Epoch 37/100\n",
      "1/1 - 3s - loss: 8.5621 - accuracy: 0.2061 - val_loss: 8.5977 - val_accuracy: 0.2073\n",
      "Epoch 38/100\n",
      "1/1 - 4s - loss: 8.5619 - accuracy: 0.2065 - val_loss: 8.5983 - val_accuracy: 0.2074\n",
      "Epoch 39/100\n",
      "1/1 - 3s - loss: 8.5620 - accuracy: 0.2070 - val_loss: 8.5991 - val_accuracy: 0.2078\n",
      "Epoch 40/100\n",
      "1/1 - 3s - loss: 8.5623 - accuracy: 0.2070 - val_loss: 8.5998 - val_accuracy: 0.2073\n",
      "Epoch 41/100\n",
      "1/1 - 3s - loss: 8.5626 - accuracy: 0.2069 - val_loss: 8.6003 - val_accuracy: 0.2074\n",
      "Epoch 42/100\n",
      "1/1 - 3s - loss: 8.5628 - accuracy: 0.2067 - val_loss: 8.6005 - val_accuracy: 0.2071\n",
      "Epoch 43/100\n",
      "1/1 - 3s - loss: 8.5629 - accuracy: 0.2067 - val_loss: 8.6003 - val_accuracy: 0.2073\n",
      "Epoch 44/100\n",
      "1/1 - 3s - loss: 8.5627 - accuracy: 0.2067 - val_loss: 8.5999 - val_accuracy: 0.2071\n",
      "Epoch 45/100\n",
      "1/1 - 3s - loss: 8.5624 - accuracy: 0.2067 - val_loss: 8.5993 - val_accuracy: 0.2074\n",
      "Epoch 46/100\n",
      "1/1 - 3s - loss: 8.5620 - accuracy: 0.2068 - val_loss: 8.5987 - val_accuracy: 0.2074\n",
      "Epoch 47/100\n",
      "1/1 - 3s - loss: 8.5615 - accuracy: 0.2069 - val_loss: 8.5982 - val_accuracy: 0.2075\n",
      "Epoch 48/100\n",
      "1/1 - 3s - loss: 8.5612 - accuracy: 0.2069 - val_loss: 8.5978 - val_accuracy: 0.2074\n",
      "Epoch 49/100\n",
      "1/1 - 3s - loss: 8.5610 - accuracy: 0.2069 - val_loss: 8.5974 - val_accuracy: 0.2071\n",
      "Epoch 50/100\n",
      "1/1 - 3s - loss: 8.5608 - accuracy: 0.2067 - val_loss: 8.5972 - val_accuracy: 0.2074\n",
      "Epoch 51/100\n",
      "1/1 - 3s - loss: 8.5607 - accuracy: 0.2064 - val_loss: 8.5972 - val_accuracy: 0.2071\n",
      "Epoch 52/100\n",
      "1/1 - 3s - loss: 8.5607 - accuracy: 0.2063 - val_loss: 8.5972 - val_accuracy: 0.2070\n",
      "Epoch 53/100\n",
      "1/1 - 3s - loss: 8.5607 - accuracy: 0.2062 - val_loss: 8.5972 - val_accuracy: 0.2068\n",
      "Epoch 54/100\n",
      "1/1 - 4s - loss: 8.5607 - accuracy: 0.2061 - val_loss: 8.5972 - val_accuracy: 0.2067\n",
      "Epoch 55/100\n",
      "1/1 - 3s - loss: 8.5606 - accuracy: 0.2060 - val_loss: 8.5973 - val_accuracy: 0.2067\n",
      "Epoch 56/100\n",
      "1/1 - 3s - loss: 8.5605 - accuracy: 0.2060 - val_loss: 8.5972 - val_accuracy: 0.2067\n",
      "Epoch 57/100\n",
      "1/1 - 3s - loss: 8.5604 - accuracy: 0.2061 - val_loss: 8.5971 - val_accuracy: 0.2069\n",
      "Epoch 58/100\n",
      "1/1 - 3s - loss: 8.5602 - accuracy: 0.2063 - val_loss: 8.5969 - val_accuracy: 0.2071\n",
      "Epoch 59/100\n",
      "1/1 - 3s - loss: 8.5600 - accuracy: 0.2064 - val_loss: 8.5967 - val_accuracy: 0.2074\n",
      "Epoch 60/100\n",
      "1/1 - 3s - loss: 8.5598 - accuracy: 0.2064 - val_loss: 8.5966 - val_accuracy: 0.2076\n",
      "Epoch 61/100\n",
      "1/1 - 3s - loss: 8.5596 - accuracy: 0.2066 - val_loss: 8.5965 - val_accuracy: 0.2074\n",
      "Epoch 62/100\n",
      "1/1 - 3s - loss: 8.5594 - accuracy: 0.2068 - val_loss: 8.5965 - val_accuracy: 0.2074\n",
      "Epoch 63/100\n",
      "1/1 - 3s - loss: 8.5592 - accuracy: 0.2070 - val_loss: 8.5966 - val_accuracy: 0.2077\n",
      "Epoch 64/100\n",
      "1/1 - 3s - loss: 8.5591 - accuracy: 0.2072 - val_loss: 8.5966 - val_accuracy: 0.2077\n",
      "Epoch 65/100\n",
      "1/1 - 3s - loss: 8.5591 - accuracy: 0.2074 - val_loss: 8.5966 - val_accuracy: 0.2078\n",
      "Epoch 66/100\n",
      "1/1 - 4s - loss: 8.5590 - accuracy: 0.2075 - val_loss: 8.5966 - val_accuracy: 0.2079\n",
      "Epoch 67/100\n",
      "1/1 - 3s - loss: 8.5589 - accuracy: 0.2076 - val_loss: 8.5965 - val_accuracy: 0.2080\n",
      "Epoch 68/100\n"
     ]
    }
   ],
   "source": [
    "model.fit((np.squeeze(independent_training_data,axis=0)),(np.squeeze(dependent_training_data,axis=0)), epochs=100,\n",
    "          batch_size = 60000,steps_per_epoch=1,\n",
    "         validation_data = ((np.squeeze(independent_testing_data,axis=0)),(dependent_testing_data)),\n",
    "         validation_steps =1,verbose=2)\n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
